{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5536c159",
   "metadata": {},
   "source": [
    "# Collaborative Filtering Recommender Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2137a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb2aaa0-67ef-4293-a803-84bc593c2531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "movies_df = pd.read_csv('movies.csv')\n",
    "ratings_df = pd.read_csv('ratings.csv')\n",
    "\n",
    "# Pre-processing index\n",
    "unique_movie_ids = ratings_df['movieId'].unique()\n",
    "unique_user_ids = ratings_df['userId'].unique()\n",
    "movie_to_idx = {original_id: i for i, original_id in enumerate(unique_movie_ids)}\n",
    "user_to_idx = {original_id: i for i, original_id in enumerate(unique_user_ids)}\n",
    "\n",
    "# Dimension matrix\n",
    "num_movies = len(unique_movie_ids)\n",
    "num_users = len(unique_user_ids)\n",
    "\n",
    "\n",
    "# Initialize Y R.\n",
    "Y = np.zeros((num_movies, num_users))\n",
    "R = np.zeros((num_movies, num_users))\n",
    "\n",
    "\n",
    "for index, row in ratings_df.iterrows():\n",
    "    original_movie_id = row['movieId']\n",
    "    original_user_id = row['userId']\n",
    "    rating = row['rating']\n",
    "    movie_idx = movie_to_idx[original_movie_id]\n",
    "    user_idx = user_to_idx[original_user_id]\n",
    "    Y[movie_idx, user_idx] = rating\n",
    "    R[movie_idx, user_idx] = 1\n",
    "\n",
    "print(f\"Y : {Y.shape}\")\n",
    "print(f\"R : {R.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235674ce-f289-4668-bf53-becae8b4d937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Normalization for Y : \n",
    "# Y_mean : average of a movie from many people's perspective.\n",
    "# Y_norm = Y_real - Y_mean\n",
    "# handle problem : \"Cold Start\".\n",
    "\n",
    "def normalize_ratings(Y, R):\n",
    "    num_movies, num_users = Y.shape\n",
    "    \n",
    "    # Initialize\n",
    "    Y_mean = np.zeros((num_movies, 1))\n",
    "    Y_norm = np.zeros((num_movies, num_users))\n",
    "    \n",
    "    for i in range(num_movies):\n",
    "        idx = np.where(R[i, :] == 1)[0]\n",
    "        \n",
    "        if len(idx) > 0:\n",
    "            mean_val = np.mean(Y[i, idx])\n",
    "            Y_mean[i] = mean_val\n",
    "            \n",
    "            Y_norm[i, idx] = Y[i, idx] - mean_val\n",
    "        else:\n",
    "            Y_mean[i] = 0\n",
    "            \n",
    "    return Y_norm, Y_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfefcf9-46ec-4084-be7a-5d2163937039",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 10 # number of features.\n",
    "# Each row is a film, contains 10 features.\n",
    "X = np.random.randn(num_movies, num_features) * 0.1\n",
    "# Each row is a person, contains 10 prefers.\n",
    "W = np.random.randn(num_users, num_features) * 0.1\n",
    "# Bias\n",
    "b = np.random.randn(1, num_users) * 0.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c48e1f-10b5-49f0-ae42-7ecc8e2529e4",
   "metadata": {},
   "source": [
    "$J({\\mathbf{x}^{(0)},...,\\mathbf{x}^{(n_m-1)},\\mathbf{w}^{(0)},b^{(0)},...,\\mathbf{w}^{(n_u-1)},b^{(n_u-1)}})= \\left[ \\frac{1}{2}\\sum_{(i,j):r(i,j)=1}(\\mathbf{w}^{(j)} \\cdot \\mathbf{x}^{(i)} + b^{(j)} - y^{(i,j)})^2 \\right]\n",
    "+ \\underbrace{\\left[\n",
    "\\frac{\\lambda}{2}\n",
    "\\sum_{j=0}^{n_u-1}\\sum_{k=0}^{n-1}(\\mathbf{w}^{(j)}_k)^2\n",
    "+ \\frac{\\lambda}{2}\\sum_{i=0}^{n_m-1}\\sum_{k=0}^{n-1}(\\mathbf{x}_k^{(i)})^2\n",
    "\\right]}_{regularization}$\n",
    "\n",
    "Other way : \n",
    "\n",
    "$= \\left[ \\frac{1}{2}\\sum_{j=0}^{n_u-1} \\sum_{i=0}^{n_m-1}r(i,j)*(\\mathbf{w}^{(j)} \\cdot \\mathbf{x}^{(i)} + b^{(j)} - y^{(i,j)})^2 \\right]\n",
    "+\\text{regularization}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e64b965-d0a2-4dce-9bfb-1326ad9f93e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(X, W, b, Y, R, lambda_):\n",
    "    \"\"\"\n",
    "    Returns the cost for the content-based filtering\n",
    "    Args:\n",
    "      X (ndarray (num_movies,num_features)): matrix of item features\n",
    "      W (ndarray (num_users,num_features)) : matrix of user parameters\n",
    "      b (ndarray (1, num_users)            : vector of user parameters\n",
    "      Y (ndarray (num_movies,num_users)    : matrix of user ratings of movies\n",
    "      R (ndarray (num_movies,num_users)    : matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user\n",
    "      lambda_ (float): regularization parameter\n",
    "    Returns:\n",
    "      J (float) : Cost\n",
    "    \"\"\"\n",
    "    nm, nu = Y.shape\n",
    "    J = 0\n",
    "    Prediction_Error = 0.0\n",
    "    for i in range(nu) : \n",
    "        for j in range(nm) : \n",
    "            Prediction_Error += ( R[j, i] * ( np.dot(W[i, : ],X[j, : ]) + b[0, i] - Y[j, i] )**2  )\n",
    "    Prediction_Error *= 0.5\n",
    "    \n",
    "    Regularization = 0.0\n",
    "    for j in range(nu) : \n",
    "        for k in range(len(W[0, :])) : \n",
    "            Regularization += W[j, k]**2\n",
    "            \n",
    "    for i in range(nm) : \n",
    "        for k in range(len(X[0, :])) : \n",
    "            Regularization += X[i, k]**2\n",
    "    \n",
    "    Regularization *= (lambda_ / 2)\n",
    "    J += (Prediction_Error + Regularization)\n",
    "\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7854c2e-b3bb-449b-b9a0-dffd66a44152",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users_r = 4\n",
    "num_movies_r = 5 \n",
    "num_features_r = 3\n",
    "\n",
    "X_r = X[:num_movies_r, :num_features_r]\n",
    "W_r = W[:num_users_r,  :num_features_r]\n",
    "b_r = b[0, :num_users_r].reshape(1,-1)\n",
    "Y_r = Y[:num_movies_r, :num_users_r]\n",
    "R_r = R[:num_movies_r, :num_users_r]\n",
    "\n",
    "# Evaluate cost function no regularization\n",
    "J = cost_function(X_r, W_r, b_r, Y_r, R_r, 0);\n",
    "print(f\"Cost: {J:0.2f}\")\n",
    "# Evaluate cost function with regularization \n",
    "J = cost_function(X_r, W_r, b_r, Y_r, R_r, 1.5);\n",
    "print(f\"Cost (with regularization): {J:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a6b35c-a28a-4f94-a060-e657f3d6b506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function_vectorized(X, W, b, Y, R, lambda_):\n",
    "    # X (Movies x Features) @ W.T (Features x Users) -> (Movies x Users)\n",
    "    prediction = np.dot(X, W.T) + b\n",
    "    \n",
    "    diff = (prediction - Y)\n",
    "    J = 0.5 * np.sum((diff * R) ** 2)\n",
    "    \n",
    "    #Regularization\n",
    "    reg_term = (lambda_ / 2) * (np.sum(W**2) + np.sum(X**2))\n",
    "    \n",
    "    J = J + reg_term\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973e4d2d-51a0-4d81-99bc-96511ef4cf92",
   "metadata": {},
   "source": [
    "$E_{ij} = r(i,j)\\,\\big( (W X^\\top)_{j,i} + b_j - Y_{i,j} \\big)$\n",
    "\n",
    "$\\frac{\\partial J}{\\partial X} = (\\text{Error} \\cdot W) + \\lambda X$  \n",
    "\n",
    "$\\frac{\\partial J}{\\partial W} = (\\text{Error}^T \\cdot X) + \\lambda W$  \n",
    "\n",
    "$\\frac{\\partial J}{\\partial b} = \\sum \\text{Error}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2a1350-b037-488f-872c-9138848cfe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X, W, b, Y, R, lambda_) : \n",
    "    prediction = np.dot(X, W.T) + b\n",
    "    error = (prediction - Y) * R # skip empty cell\n",
    "    \n",
    "    grad_X = np.dot(error,W) + (lambda_ * X)\n",
    "    grad_W = np.dot(error.T, X) + (lambda_ * W)\n",
    "    grad_b = np.sum(error, axis=0, keepdims=True)\n",
    "\n",
    "    return grad_X, grad_W, grad_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd4e30c-9234-4aff-a5b1-55a3930d549d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, W, b, Y, R, max_iters, lr, lambda_) :\n",
    "    J_history = []\n",
    "\n",
    "    for i in range(max_iters): \n",
    "        \n",
    "        grad_X, grad_W, grad_b = compute_gradient(X, W, b, Y, R, lambda_) \n",
    "        X = X - lr * grad_X\n",
    "        W = W - lr * grad_W\n",
    "        b = b - lr * grad_b\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            cost = cost_function_vectorized(X, W, b, Y, R, lambda_)\n",
    "            J_history.append(cost)\n",
    "            print(f\"Iteration {i:4d}: Cost {cost:8.2f}\")\n",
    "\n",
    "\n",
    "    return X, W, b, J_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c27978-4471-49ee-894f-b73d79a40326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stochastic_gradient_descent(X, W, b, Y, R, max_epochs, alpha, lambda_):\n",
    "#     idxs = np.argwhere(R == 1)\n",
    "#     J_history = []\n",
    "#     for epoch in range(max_epochs):\n",
    "#         # Shuffle\n",
    "#         np.random.shuffle(idxs)\n",
    "        \n",
    "#         for (i, j) in idxs:\n",
    "#             # i: Movie index, j: User index\n",
    "            \n",
    "#             prediction = np.dot(X[i], W[j]) + b[0, j]\n",
    "#             error = prediction - Y[i, j]\n",
    "            \n",
    "\n",
    "#             w_j_old = W[j].copy()\n",
    "#             x_i_old = X[i].copy()\n",
    "            \n",
    "#             # Update W[j]\n",
    "#             W[j] = w_j_old - alpha * (error * x_i_old + lambda_ * w_j_old)\n",
    "            \n",
    "#             # Update X[i]\n",
    "#             X[i] = x_i_old - alpha * (error * w_j_old + lambda_ * x_i_old)\n",
    "            \n",
    "#             # Update b[j]\n",
    "#             b[0, j] = b[0, j] - alpha * error\n",
    "            \n",
    "\n",
    "#         if epoch % 5 == 0:\n",
    "#             cost = cost_function_vectorized(X, W, b, Y, R, lambda_)\n",
    "#             J_history.append(cost)\n",
    "#             print(f\"Epoch {epoch:4d}: Cost {cost:8.2f}\")\n",
    "            \n",
    "#     return X, W, b, J_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79207eb-4d03-4362-a882-2e2a553cd114",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4         # Learning Rate\n",
    "lambda_ = 1       # Regularization\n",
    "alpha = 0.001\n",
    "iterations = 300  \n",
    "max_epochs = 20\n",
    "Y_norm, Y_mean = normalize_ratings(Y, R)\n",
    "\n",
    "X_train, W_train, b_train, J_hist = gradient_descent(X, W, b, Y_norm, R, iterations, lr, lambda_)\n",
    "print(J_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b17c69-79c0-46cc-8032-eb777bbbd1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(J_hist)\n",
    "plt.xlabel(\"Iterations \")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e340013-8857-41b9-83d9-265eca7e6a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_norm = np.dot(X_train, W_train.T) + b_train\n",
    "p_final = np.clip(p_norm + Y_mean, 0.5, 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1475a7a9-65d6-48c3-893e-0426eb028fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test w user has index = 0\n",
    "my_user_id = 0\n",
    "\n",
    "# get the list of movies this person HAS watched and rated highly (>= 4 stars)\n",
    "# use the original Y matrix\n",
    "rated_indices = np.where(Y[:, my_user_id] >= 2)[0]\n",
    "\n",
    "print(f\"\\n--- USER {my_user_id} LIKED THE MOVIES ---\")\n",
    "for idx in rated_indices[:10]: \n",
    "    original_id = list(movie_to_idx.keys())[list(movie_to_idx.values()).index(idx)]\n",
    "    title = movies_df[movies_df['movieId'] == original_id]['title'].values[0]\n",
    "    print(f\"{title} (Rated: {Y[idx, my_user_id]})\")\n",
    "\n",
    "# get the list of movies this machine suggest\n",
    "# filter unwatched movies (R = 0)\n",
    "prediction_for_user = p_final[:, my_user_id]\n",
    "# assign watched movies score = -1 to not suggest again\n",
    "prediction_for_user[R[:, my_user_id] == 1] = -1 \n",
    "\n",
    "# ranking top 10 : \n",
    "top_10_indices = np.argsort(prediction_for_user)[-10:][::-1]\n",
    "\n",
    "print(f\"\\n--- SUGGESTION SYSTEM FOR USER {my_user_id} ---\")\n",
    "for idx in top_10_indices:\n",
    "    original_id = list(movie_to_idx.keys())[list(movie_to_idx.values()).index(idx)]\n",
    "    title = movies_df[movies_df['movieId'] == original_id]['title'].values[0]\n",
    "    predicted_score = prediction_for_user[idx]\n",
    "    print(f\"{title} (Prediction: {predicted_score:.1f} star)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ad5ad3-dfde-4a63-ad5c-ec0393f48c26",
   "metadata": {},
   "source": [
    "## USE TENSORFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbbcdd2-6e60-46ff-8b17-bb9789258c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f798453-9300-4c5b-8eb9-dda6126f767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cofi_cost_func_tf(X, W, b, Y, R, lambda_):\n",
    "    \"\"\"\n",
    "    Returns the cost for the content-based filtering\n",
    "    Vectorized for speed. Uses tensorflow operations to be compatible with custom training loop.\n",
    "    Args:\n",
    "      X (ndarray (num_movies,num_features)): matrix of item features\n",
    "      W (ndarray (num_users,num_features)) : matrix of user parameters\n",
    "      b (ndarray (1, num_users)            : vector of user parameters\n",
    "      Y (ndarray (num_movies,num_users)    : matrix of user ratings of movies\n",
    "      R (ndarray (num_movies,num_users)    : matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user\n",
    "      lambda_ (float): regularization parameter\n",
    "    Returns:\n",
    "      J (float) : Cost\n",
    "    \"\"\"\n",
    "    j = (tf.linalg.matmul(X, tf.transpose(W)) + b - Y)*R\n",
    "    J = 0.5 * tf.reduce_sum(j**2) + (lambda_/2) * (tf.reduce_sum(X**2) + tf.reduce_sum(W**2))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183e47e7-26b6-4eb9-95ab-06db79d571ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate cost function\n",
    "J = cofi_cost_func_tf(X, W, b, Y, R, 0);\n",
    "print(f\"Cost: {J:0.2f}\")\n",
    "\n",
    "# Evaluate cost function with regularization \n",
    "J = cofi_cost_func_tf(X, W, b, Y, R, 1.5);\n",
    "print(f\"Cost (with regularization): {J:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4ef25e-ddaa-4ff0-a7a1-020815b4fb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Useful Values\n",
    "num_movies, num_users = Y.shape\n",
    "num_features = 100\n",
    "\n",
    "# Set Initial Parameters (W, X), use tf.Variable to track these variables\n",
    "tf.random.set_seed(1234) # for consistent results\n",
    "W = tf.Variable(tf.random.normal((num_users,  num_features),dtype=tf.float64),  name='W')\n",
    "X = tf.Variable(tf.random.normal((num_movies, num_features),dtype=tf.float64),  name='X')\n",
    "b = tf.Variable(tf.random.normal((1,          num_users),   dtype=tf.float64),  name='b')\n",
    "\n",
    "# Instantiate an optimizer.\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6181cf-9d56-4b97-866e-a5509ac8fb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 200\n",
    "lambda_ = 1\n",
    "for iter in range(iterations):\n",
    "    # Use TensorFlowâ€™s GradientTape\n",
    "    # to record the operations used to compute the cost \n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        # Compute the cost (forward pass included in cost)\n",
    "        cost_value = cofi_cost_func_tf(X, W, b, Y_norm, R, lambda_)\n",
    "\n",
    "    # Use the gradient tape to automatically retrieve\n",
    "    # the gradients of the trainable variables with respect to the loss\n",
    "    grads = tape.gradient( cost_value, [X,W,b] )\n",
    "\n",
    "    # Run one step of gradient descent by updating\n",
    "    # the value of the variables to minimize the loss.\n",
    "    optimizer.apply_gradients( zip(grads, [X,W,b]) )\n",
    "\n",
    "    # Log periodically.\n",
    "    if iter % 20 == 0:\n",
    "        print(f\"Training loss at iteration {iter}: {cost_value:0.1f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
